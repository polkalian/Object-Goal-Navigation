We thank the reviewer for the further concern. Regarding the intuition of model design, one of our purposes of applying the integrated intent is to provide the high-level policy with information of low-level decision-making (L188). We agree that the integrated intent overlooks the low-level comprehension of agent's state, although the agent can access the state information through the high-level GRU memories. Thus we modify CaMP as a baseline where the master policy takes in the sum of memories from sub-policy GRUs weighted by the intent of the master policy: 

$P(i_t)=F(\sum_{\omega^{j} \in \Omega}h_{t}^{\omega^{j}}\cdot P(\omega^{\prime}_{t}=\omega^{j}))$

where $h_{t}^{\omega^{j}}$  denotes the memory of sub-policy $\omega^{j}$ corresponding to equation (7). We embed the memories with a linear model $F(\cdot)$ to match the size of integrated intent, so that we can train the new model by fine-tuning CaMP with its parameters (given the limited time). We train the model (referred to as CaMP-me) for 2 million steps on the validation set and report the testing results in the table below.

|  |  | All |  |  |  | Hard(N $\geq$ 4) |  |
|:---:|:---:|:---:|:---:|---|:---:|:---:|:---:|
| Methods | SR(%) | SPL | FDT |  | SR(%) | SPL | FDT |
| CaMP | 56.3 | 0.327 | 3.67 |  | 41.4 | 0.231 | 5.76 |
| CaMP-mem |  |  |  |  |  |  |  |

On the other side, an agent with counterfactual policy makes decisions based on its own intent (unexecuted action) rather than the intermediate variables (e.g. hidden features, memories) since the intent is the only "blind spot" of the decision-making process. For instance, it's true that the GRU memories may "encapsulate the holistic context such as visited states or environment configuration". However, even if the agent's memories are not provided through intent, the exactly same memories will be generated by GRU later and help the agent understand the states (regardless of HRL). And the GRU is trained for the purpose of utilizing memories to better encode the states. On the contrary, since the action logits are the end results of the policy, the comprehension of  "last mile" decision-making is invisible for the agent, which makes the intent particularly valuable. 
